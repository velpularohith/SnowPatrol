{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create some Fake Data\n",
    "\n",
    "This can be used to run some validations about the logic before getting real customer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create files in local file system in CSV format just for referece, as we will be writing those into Snowflake tables later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_app_logs (n_users, n_days_ago, random_state=0, faker_state = 0):\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    fake = Faker()\n",
    "    Faker.seed(faker_state)\n",
    "    today = pd.Timestamp(datetime.now().date())\n",
    "    \n",
    "    employee_list = []\n",
    "    app_list = []\n",
    "    \n",
    "    for user in range(1, n_users):\n",
    "        user_email = fake.ascii_company_email()\n",
    "        department = fake.company()\n",
    "        division = fake.job()\n",
    "        title = fake.job()\n",
    "        \n",
    "        has_leaved_company = np.random.uniform (0,100)\n",
    "        if (has_leaved_company < 5): #Generate 5% people leaving the company \n",
    "            last_day_work_days = np.random.uniform (0, n_days_ago)\n",
    "            field_last_work_day = today - timedelta (days = day)\n",
    "        else:\n",
    "            last_day_work_days = 0\n",
    "            field_last_work_day = today + timedelta (days = 365) # set to the future for now\n",
    "        \n",
    "        n_logings = int(np.random.uniform (0, n_days_ago - last_day_work_days))  # Between never logging and every day\n",
    "        \n",
    "        for l in range (0, n_logings):\n",
    "            day = np.random.uniform(0, n_days_ago) # get a ramdom day\n",
    "            \n",
    "            ## Let´s introduce some users who do not log in thet last 30 days\n",
    "            not_loggin = np.random.uniform (0,100)\n",
    "            if (not_loggin < 25):\n",
    "                login_day = today - timedelta (days = day + last_day_work_days + 50)\n",
    "            else:\n",
    "                login_day = today - timedelta (days = day + last_day_work_days)\n",
    "            app_list.append([user_email, login_day])\n",
    "            \n",
    "        employee_list.append([user_email, department, division, title, field_last_work_day])\n",
    "        \n",
    "    df_employee = pd.DataFrame(employee_list, columns = ['session_user', 'department', 'division', 'title', 'last_day_of_work'])\n",
    "    df_app = pd.DataFrame(app_list, columns = ['session_user', 'snapshot_datetime'])\n",
    "    \n",
    "    return df_app, df_employee\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_app_1, df_employee = generate_app_logs (n_users=5000, n_days_ago =365, random_state= 6, faker_state= 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_app_1.to_csv('../../data/sample_okta_logs.csv', index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employee.to_csv('../../data/sample_employee_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_app_2, k = generate_app_logs (n_users=5000, n_days_ago =365, random_state= 19, faker_state= 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_app_2.to_csv('../../data/sample_app_logs.csv', index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_working_days (n_days_ago = 365):\n",
    "    \n",
    "    today = pd.Timestamp(datetime.now().date())\n",
    "    \n",
    "    calendar_list = []\n",
    "    \n",
    "    for d in range(0, n_days_ago):    \n",
    "        calendar_day = today - timedelta (days = d)\n",
    "                \n",
    "        num = np.random.uniform (0,100)\n",
    "        if (num < 20): # 20% of holidays\n",
    "            is_working_day = 0\n",
    "        else:\n",
    "            is_working_day = 1\n",
    "        \n",
    "        calendar_list.append([calendar_day, is_working_day])\n",
    "        \n",
    "    \n",
    "    df_cal = pd.DataFrame(calendar_list, columns = ['snapshot_datetime', 'work_day'])\n",
    "    \n",
    "    return df_cal    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal = generate_working_days(n_days_ago = 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_datetime</th>\n",
       "      <th>work_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2022-06-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2022-06-06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2022-06-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2022-06-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2022-06-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    snapshot_datetime  work_day\n",
       "0          2023-06-02         1\n",
       "1          2023-06-01         1\n",
       "2          2023-05-31         1\n",
       "3          2023-05-30         1\n",
       "4          2023-05-29         1\n",
       "..                ...       ...\n",
       "360        2022-06-07         1\n",
       "361        2022-06-06         1\n",
       "362        2022-06-05         0\n",
       "363        2022-06-04         1\n",
       "364        2022-06-03         1\n",
       "\n",
       "[365 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal.to_csv('../../data/sample_work_days.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.functions as F\n",
    "import snowflake.snowpark.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../config/creds_cc.json', 'r') as ff:\n",
    "    conn_param=json.load(ff)\n",
    "\n",
    "session = Session.builder.configs(conn_param).create() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\"create or replace database dev_snowpatrol\").collect()\n",
    "session.sql(\"create or replace schema main\").collect()\n",
    "\n",
    "session.use_database(\"dev_snowpatrol\")\n",
    "session.use_schema(\"dev_snowpatrol.main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.table.Table at 0x7fcb116ba0d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/sample_okta_logs.csv')\n",
    "df.columns = df.columns.str.upper()\n",
    "\n",
    "table_name = 'SAMPLE_OKTA_LOGS'\n",
    "\n",
    "session.write_pandas(df, table_name, auto_create_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.table.Table at 0x7fcb116ba7f0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/sample_work_days.csv')\n",
    "df.columns = df.columns.str.upper()\n",
    "\n",
    "table_name = 'SAMPLE_WORK_DAYS'\n",
    "\n",
    "session.write_pandas(df, table_name, auto_create_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.table.Table at 0x7fcb116ba3d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/sample_app_logs.csv')\n",
    "df.columns = df.columns.str.upper()\n",
    "\n",
    "table_name = 'SAMPLE_APP_LOGS'\n",
    "\n",
    "session.write_pandas(df, table_name, auto_create_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.table.Table at 0x7fcb12f591c0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/sample_employee_metadata.csv')\n",
    "df.columns = df.columns.str.upper()\n",
    "\n",
    "table_name = 'SAMPLE_EMPLOYEE_METADATA'\n",
    "\n",
    "session.write_pandas(df, table_name, auto_create_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
